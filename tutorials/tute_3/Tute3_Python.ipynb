{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Science (MAST30034) Tutorial 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statsmodels` (30-45 minutes):\n",
    "- Linear Regression\n",
    "- Evaluation Metrics\n",
    "- Penalized Regression (LASSO and Ridge)\n",
    "\n",
    "`pyspark.ml` (Experimental) (15 minutes):\n",
    "- Linear Regression\n",
    "\n",
    "Project 1 Report (Remainder of Tutorial):\n",
    "- Questions\n",
    "- Ongoing feedback.\n",
    "\n",
    "Optional Content for Students:\n",
    "- Generalised Linear Models (GLM) with `statsmodels`\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:56:40.074555Z",
     "start_time": "2022-07-18T07:56:40.068541Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.formula.api import ols, glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:56.715236Z",
     "start_time": "2022-07-18T07:52:56.695504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "RatecodeID                      float64\n",
       "store_and_fwd_flag               object\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "airport_fee                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/tute_data/sample_data.parquet\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's try to predict `total_amount` using `fare_amount, tip_amount, toll_amount, trip_distance, VendorID` as predictors.\n",
    "\n",
    "Some things to take note:\n",
    "- `tip_amount` is only valid for `payment_type == 1` (card)\n",
    "- `VendorID` is categorical, with only two possible values (`1` or `2`) so we should make it boolean\n",
    "\n",
    "**Whilst you may use this as an example, please do not copy this as it is incorrect.**\n",
    "\n",
    "How so? Discuss as a class the implications of predicting `total_amount` given the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:56.730594Z",
     "start_time": "2022-07-18T07:52:56.717962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92981</th>\n",
       "      <td>24.95</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92982</th>\n",
       "      <td>11.15</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92983</th>\n",
       "      <td>42.10</td>\n",
       "      <td>28.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.55</td>\n",
       "      <td>9.30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92984</th>\n",
       "      <td>15.36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92985</th>\n",
       "      <td>11.16</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_amount  fare_amount  tip_amount  tolls_amount  trip_distance  \\\n",
       "92981         24.95         17.0        4.15          0.00           5.10   \n",
       "92982         11.15          5.5        1.85          0.00           1.00   \n",
       "92983         42.10         28.5        2.00          6.55           9.30   \n",
       "92984         15.36          9.0        2.56          0.00           2.50   \n",
       "92985         11.16          5.5        1.86          0.00           1.02   \n",
       "\n",
       "       VendorID  \n",
       "92981      True  \n",
       "92982      True  \n",
       "92983      True  \n",
       "92984      True  \n",
       "92985     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataframe\n",
    "COL_FILTER = ['total_amount', 'fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "df_filtered = df.loc[df['payment_type'] == 1, COL_FILTER].reset_index(drop=True)\n",
    "\n",
    "# same as df_filtered['VendorID'].astype(bool)\n",
    "df_filtered['VendorID'] = df_filtered['VendorID'] == 1 \n",
    "\n",
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are looking for linear relationships between our chosen response `total_amount`.   \n",
    "- Now I'm not sure what kind of life you've lived, but I'm fairly certain that we can infer that `total_amount` will have a positive linear relationship with `fare_amount`. Let's see a quick plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:56.817579Z",
     "start_time": "2022-07-18T07:52:56.731487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered[['total_amount', 'fare_amount']].plot.scatter(x='fare_amount', y='total_amount')\n",
    "plt.show()\n",
    "\n",
    "# linear rel as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, obviously this looks like an overall positive linear relationship. How might we statistically test this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `R`, we would do something like this for (Ordinary) Least Squares:\n",
    "```R\n",
    ">>> fit <- lm(total_amount~fare_amount + tip_amount + tolls_amount + trip_distance + VendorID ,data=dat_fit)\n",
    ">>> summary(fit)\n",
    "```\n",
    "```\n",
    "Call:\n",
    "lm(formula = total_amount ~ fare_amount + tip_amount + tolls_amount +\n",
    "trip_distance + VendorID, data = dat_fit)\n",
    "\n",
    "Residuals:\n",
    "Min     1Q      Median  3Q     Max\n",
    "-1.4727 -0.3295 -0.1528 0.1747 1.7975\n",
    "\n",
    "Coefficients:\n",
    "               Estimate Std. Error t value Pr(>|t|)\n",
    "(Intercept)    1.162154   0.002986 389.194  <2e-16 ***\n",
    "fare_amount    0.993388   0.000315 3153.943 <2e-16 ***\n",
    "tip_amount     1.006511   0.000826 1218.553 <2e-16 ***\n",
    "tolls_amount   0.979325   0.001285 762.428  <2e-16 ***\n",
    "trip_distance  0.011742   0.000963 12.194   <2e-16 ***\n",
    "VendorIDTRUE  -0.003125   0.002914 -1.073    0.283\n",
    "---\n",
    "Signif. codes:\n",
    "0 ^a˘A¨Y***^a˘A´Z 0.001 ^a˘A¨Y**^a˘A´Z 0.01 ^a˘A¨Y*^a˘A´Z 0.05 ^a˘A¨Y.^a˘A´Z 0.1 ^a˘A¨Y ^a˘A´Z 1\n",
    "\n",
    "Residual standard error: 0.362 on 61886 degrees of freedom\n",
    "Multiple R-squared: 0.9994,          Adjusted R-squared: 0.9994\n",
    "F-statistic: 1.953e+07 on 5 and 61886 DF, p-value: < 2.2e-16\n",
    "```\n",
    "\n",
    "Note: This example from `R` uses an older dataset hence different values to the Python output below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation Source: https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html?highlight=ols#statsmodels.regression.linear_model.OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:56.869576Z",
     "start_time": "2022-07-18T07:52:56.818695Z"
    }
   },
   "outputs": [],
   "source": [
    "fit = ols(\n",
    "    formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance + VendorID\",\n",
    "    data=df_filtered\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:56.988049Z",
     "start_time": "2022-07-18T07:52:56.903408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 8.111e+06\n",
      "Date:                Wed, 10 Aug 2022   Prob (F-statistic):               0.00\n",
      "Time:                        11:30:32   Log-Likelihood:            -1.0380e+05\n",
      "No. Observations:               92986   AIC:                         2.076e+05\n",
      "Df Residuals:                   92980   BIC:                         2.077e+05\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            3.6262      0.004    842.811      0.000       3.618       3.635\n",
      "VendorID[T.True]    -0.0610      0.005    -11.557      0.000      -0.071      -0.051\n",
      "fare_amount          0.9775      0.000   2849.239      0.000       0.977       0.978\n",
      "tip_amount           1.0352      0.001    928.310      0.000       1.033       1.037\n",
      "tolls_amount         1.0404      0.002    565.826      0.000       1.037       1.044\n",
      "trip_distance        0.0330      0.001     39.043      0.000       0.031       0.035\n",
      "==============================================================================\n",
      "Omnibus:                    22330.967   Durbin-Watson:                   1.386\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1435112.916\n",
      "Skew:                          -0.088   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.245   Cond. No.                         44.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion Questions:\n",
    "1. Is this model good? Discuss $R^2$, AIC, and Hypothesis Testing.\n",
    "    \n",
    "2. How might we improve this model? Discuss what we can do with the current features / engineered features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:57.073252Z",
     "start_time": "2022-07-18T07:52:56.994715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 1.012e+07\n",
      "Date:                Wed, 10 Aug 2022   Prob (F-statistic):               0.00\n",
      "Time:                        11:30:40   Log-Likelihood:            -1.0386e+05\n",
      "No. Observations:               92986   AIC:                         2.077e+05\n",
      "Df Residuals:                   92981   BIC:                         2.078e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.6071      0.004    907.201      0.000       3.599       3.615\n",
      "fare_amount       0.9774      0.000   2847.277      0.000       0.977       0.978\n",
      "tip_amount        1.0356      0.001    928.366      0.000       1.033       1.038\n",
      "tolls_amount      1.0402      0.002    565.334      0.000       1.037       1.044\n",
      "trip_distance     0.0331      0.001     39.090      0.000       0.031       0.035\n",
      "==============================================================================\n",
      "Omnibus:                    22427.464   Durbin-Watson:                   1.386\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1453509.044\n",
      "Skew:                          -0.101   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.368   Cond. No.                         31.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# let's try another model without VendorID\n",
    "fitter = ols(\n",
    "    formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance\",\n",
    "    data=df_filtered\n",
    ").fit()\n",
    "\n",
    "print(fitter.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have to values of AIC to compare with, which one is better...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From this model, you can't see that some are not relevant \n",
    "# Vendor ID not relevant \n",
    "# tip_amount not included in confidence interval \n",
    "# high degree of corr between fare amount and trip distance \n",
    "# this statistical testing makes no sense in the context of the data \n",
    "# remove vendor ID from the predictive model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:57.095241Z",
     "start_time": "2022-07-18T07:52:57.082241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207608.10719375586, 207739.57404300687, 'abs diff: 131.46684925101')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.aic, fitter.aic, f\"abs diff: {abs(fitter.aic - fit.aic)}\"\n",
    "\n",
    "#pick fitter model in practice \n",
    "# dropping vendor ID is logical, even though the statistics make no sense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T02:30:51.354558Z",
     "start_time": "2021-08-10T02:30:51.351370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([207608.10719375586, 207739.57404300687],\n",
       " [207664.74841909486, 207786.77506412272])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fit.aic, fitter.aic], [fit.bic, fitter.bic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Regression\n",
    "- (From a machine learning perspective) Given a data distribution $\\mathcal{D}$, predefined model hypothesis class $\\mathcal{B}$, a loss function $\\ell$. The goal of machine learning (aka modelling) is to find parameter $\\beta^*$ such that,\n",
    "  $$\\beta^* = \\text{argmin}_{\\beta\\in\\mathcal{B}} \\mathbb{E}_{(x,y)\\in \\mathcal{D}}\\{\\ell(y, f_{\\beta}(x))\\}$$\n",
    "- In reality, we don't have $\\mathcal{D}$, but only a dataset $\\mathbb{(X, Y)}$ where $(x_i, y_i) \\sim \\mathcal{D}$. And we empirically compute, \n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta\\in\\mathcal{B}} \\sum_{(x,y)\\in (\\mathbb{X, Y})}\\ell(y, f_{\\beta}(x))$$\n",
    "  In the hope that, $\\hat\\beta^*$ is close to $\\beta^*$. So for any unseen $(x, y) \\sim \\mathcal{D}$, our model is still optimal.\n",
    "- This implies that a more complicated $\\hat\\beta^*$ (blue) might not correspond to actual optimal parameters $\\beta^*$ (green).\n",
    "  - <img src=\"../../media/regularization.png\" alt=\"regularization\" style=\"width: 400px;\"/>\n",
    "  - In practice, a simpler model often explains ground truth better. We call the techniques to simplify model *regularization*.\n",
    "- For linear regression model, LASSO and Ridge are two common techniques to regularize model.\n",
    "  - Discussion: What is formula of $f_{\\beta}(x)$, $\\ell(\\cdot, \\cdot)$ for linear regression?\n",
    "  - Extension: Can you also define them for LASSO/Ridge regressions?\n",
    "\n",
    "MAST30025 Revision:\n",
    "- Lecture 4 (variable selection)\n",
    "- LSM topic 5 (`ch05_handout`) slide 141/141\n",
    "- An excellent explanation on Ridge / LASSO: https://www.youtube.com/watch?v=9LNpiiKCQUo (recommended at x1.25 speed)\n",
    "\n",
    "### LASSO ($\\ell_1$)\n",
    "- Regularizes coefficient magnitude with $\\ell_1$ loss,\n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\mathcal{B}} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda  ||\\beta||_1$$\n",
    "- LASSO encourages coefficient sparsity (setting to a value of 0).\n",
    "- Features that are collinear will result in one of them being reduced to 0 coefficient.\n",
    "- In this sense, it's quite similar to feature selection as you end up with a model that is much more simpler. \n",
    "\n",
    "### Ridge ($\\ell_2$)\n",
    "- Regularizes coefficient magnitude with $\\ell_2$ loss,\n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\mathcal{B}} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\frac{1}{2} \\lambda ||\\beta||_2^2$$\n",
    "- Ridge regression tend to shrink coefficients to a small value but not zero.\n",
    "  - Why? Can you explain this? (Tip: consider a pair of positive coefficient $\\beta=[1, \\epsilon], \\epsilon < 1$, and think about what happens to $||\\beta||_2^2$ when you subtract $\\delta \\leq \\epsilon$ from each element $\\beta$)\n",
    "- Maintaining more features, Ridge Regression is less interpretable than LASSO, but performs better in cases where there may be high multi-collinearity (i.e dependencies between attributes) or high linear correlation between certain attributes.\n",
    "- You must also ensure that we have more observations than attributes (`n > p`) as this penalty method does not drop features, leading to worse predictions. \n",
    "\n",
    "<img src=\"../../media/lasso_ridge.png\" alt=\"lassoridge\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Elastic Net\n",
    "Quick overview:\n",
    "- Combines both $\\ell_1$ and $\\ell_2$ penalty,\n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\mathcal{B}} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda_1 ||\\beta||_1 + \\frac{1}{2} \\lambda_2 ||\\beta||_2^2$$\n",
    "- Python implementation (glmnet):\n",
    "  - https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py\n",
    "  - glmnet (hyper)parameterize the loss with $\\alpha$ and $\\lambda$ instead,\n",
    "    $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\mathcal{B}} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda \\{\\alpha ||\\beta||_1 + \\frac{1}{2} (1-\\alpha) ||\\beta||_2^2\\}$$\n",
    "    - Q: How would you set the parameters if you want LASSO only?\n",
    "\n",
    "Question/Discussion:\n",
    "- How would you implement optimizer for the above objectives (LASSO, Ridge, Elastic Net)?\n",
    "- Do you need to standardize the input data? Why?\n",
    "- Is the following pseudo-code correct? Why or why not?\n",
    "  ```\n",
    "  mu <- mean(X)\n",
    "  sigma <- std(X)\n",
    "  X_std <- (X - mu) / sigma\n",
    "  X_train, X_test, y_train, y_test <- split(X_std, y)\n",
    "  model <- fit(y_train ~ X_train)\n",
    "  y_pred <- predict(model, X_test)\n",
    "  loss <- MSE(y_test, y_pred)\n",
    "  ```\n",
    "  \n",
    "- alpha is the ratio between l1 and l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:57.251463Z",
     "start_time": "2022-07-18T07:52:57.238822Z"
    }
   },
   "outputs": [],
   "source": [
    "y_cols = ['total_amount']\n",
    "x_cols = ['fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "\n",
    "# standardize (by calculating the zscore) so our data has mean 0 and var 1\n",
    "# alternatively, you can use sklearn's StandardScalar\n",
    "from scipy.stats import zscore\n",
    "\n",
    "df_standard = df_filtered[x_cols].astype(float).apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:57.290993Z",
     "start_time": "2022-07-18T07:52:57.252558Z"
    }
   },
   "outputs": [],
   "source": [
    "# format output to 4 decimal places\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "df_standard.describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `df_standard` has  $\\mu=0, \\sigma=1(=\\sigma^2)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:57.522654Z",
     "start_time": "2022-07-18T07:52:57.294040Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'glmnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v5/wmr0dngd7wb9k8_h2p9347pc0000gn/T/ipykernel_17030/1743287389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mglmnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0melastic_net_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m elastic_net_model.fit(\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'glmnet'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glmnet import ElasticNet\n",
    "\n",
    "elastic_net_model = ElasticNet(alpha=1)\n",
    "elastic_net_model.fit(\n",
    "    df_standard.values, \n",
    "    # flatten the array (from 2d matrix to 1d vector) to remove the warning message:\n",
    "    # A column-vector y was passed when a 1d array was expected.\n",
    "    df_filtered[y_cols].values.flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to look at the shrinking parameter $\\lambda$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:57.606100Z",
     "start_time": "2022-07-18T07:52:57.557325Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elastic_net_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v5/wmr0dngd7wb9k8_h2p9347pc0000gn/T/ipykernel_17030/3415268166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this can be accessed using the .lambda_best_ method after fitting!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best lambda value for LASSO: {elastic_net_model.lambda_best_[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'elastic_net_model' is not defined"
     ]
    }
   ],
   "source": [
    "# this can be accessed using the .lambda_best_ method after fitting!\n",
    "print(f'Best lambda value for LASSO: {elastic_net_model.lambda_best_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ for `ElasticNet` is computed by using cross validation (iterative approach). \n",
    "\n",
    "What about our coefficients?\n",
    "- https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:52:57.645533Z",
     "start_time": "2022-07-18T07:52:57.620201Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elastic_net_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v5/wmr0dngd7wb9k8_h2p9347pc0000gn/T/ipykernel_17030/1967221605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pd.DataFrame(\n\u001b[1;32m      2\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Intercept'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melastic_net_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melastic_net_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coefficient'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'elastic_net_model' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    index=['Intercept'] + x_cols, \n",
    "    data=[elastic_net_model.intercept_] + list(elastic_net_model.coef_), \n",
    "    columns=['Coefficient']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results.\n",
    "\n",
    "If you want to run predictions with `ElasticNet`, you can use `elastic_net_model.predict(x)` to the predict a new set of observations by passing through the `x` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficient is not 1 anymore \n",
    "# it may not be necessary to normalise all parameters in this specific case- over here it may be better to not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Spark\n",
    "Whilst using `sklearn` or `statsmodels` can be easier on a smaller sample size, using the full dataset can be quite memory intensive. For those looking to use larger datasets, using the `pyspark.ml` library may prove useful.\n",
    "\n",
    "We'll go back to the first linear model example that we did with `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:18.089054Z",
     "start_time": "2022-07-18T07:52:57.658185Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName('MAST30034 Tutorial 3')\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:23.400992Z",
     "start_time": "2022-07-18T07:53:18.090801Z"
    }
   },
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet('../../data/tlc_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like correlation from the previous tutorial, we will need to assemble a single vector for `pyspark.ml` to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:24.449109Z",
     "start_time": "2022-07-18T07:53:23.430527Z"
    }
   },
   "outputs": [],
   "source": [
    "# VectorAssembler creates new vectors from existing columns\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = 'features'\n",
    "input_cols = ['fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    # which column to combine\n",
    "    inputCols=input_cols, \n",
    "    # How should the combined columns be named\n",
    "    outputCol=features\n",
    ")\n",
    "\n",
    "model_sdf = assembler.transform(sdf.dropna('any'))\n",
    "# Display the features and targets for our model\n",
    "model_sdf.select('features').head(5), model_sdf.select('total_amount').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll start to notice that the PySpark API mirrors `sklearn`, hopefully, this doesn't seem to foreign.\n",
    "\n",
    "Pyspark Docs: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html\n",
    "\n",
    "This implementation supports both OLS, Ridge, LASSO, and Elastic Net. You can change between the models by specifying the `elasticNetParam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:24.452793Z",
     "start_time": "2022-07-18T07:53:24.450397Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "\n",
    "lm = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='total_amount'\n",
    ").fit(model_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:44.445926Z",
     "start_time": "2022-07-18T07:53:44.412399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Access coefficients\n",
    "pd.DataFrame(\n",
    "    data=[lm.intercept] + list(lm.coefficients),\n",
    "    index=['intercept'] + input_cols,\n",
    "    columns=['coefficient']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through a single prediction from the record above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:45.511354Z",
     "start_time": "2022-07-18T07:53:44.446643Z"
    }
   },
   "outputs": [],
   "source": [
    "# example record to predict\n",
    "sdf.select('total_amount', *input_cols).limit(1).show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:46.225675Z",
     "start_time": "2022-07-18T07:53:45.512416Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v5/wmr0dngd7wb9k8_h2p9347pc0000gn/T/ipykernel_17030/3905384805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# preprocess for predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredict_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m assembler = VectorAssembler(\n\u001b[1;32m      5\u001b[0m     \u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdf' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocess for predictions\n",
    "predict_test = sdf.select(*input_cols).limit(1)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=input_cols, \n",
    "    outputCol=features\n",
    ")\n",
    "\n",
    "predict_sdf = assembler.transform(predict_test).select(features)#selecting columns instead of assigning the whole dataframe\n",
    "\n",
    "predict_sdf.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `lm.transform()` to predict an `sdf` containing a single vector of features as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:46.908619Z",
     "start_time": "2022-07-18T07:53:46.226695Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = lm.transform(predict_sdf)\n",
    "predictions.show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the original record and compare the prediction vs true value.\n",
    "\n",
    "For evaluation metrics, you can use the `.summary` method. See https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegressionModel.html?highlight=ml%20summary%20regression#pyspark.ml.regression.LinearRegressionModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:46.923654Z",
     "start_time": "2022-07-18T07:53:46.909422Z"
    }
   },
   "outputs": [],
   "source": [
    "# r2 example\n",
    "lm.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:53:46.928390Z",
     "start_time": "2022-07-18T07:53:46.924481Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if you want to see the definitive list of all evaluation metrics accessible from lm.summary\n",
    "help(lm.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Notes for Revision\n",
    "#### What is the Bias-Variance tradeoff with respect to linear models:\n",
    "- Less parameters = less variance but more bias\n",
    "- More parameters = more variance but less bias\n",
    "- The goal depends on the problem, but generally we want an even variance and bias (intersection).\n",
    "\n",
    "\n",
    "#### Is using regression on X attribute / specific dataset even a good choice...?\n",
    "- The answer is yes, it is a good choice *to try*\n",
    "- BUT also try other methods...\n",
    "\n",
    "\n",
    "#### What are the pros and cons of stepwise regression?\n",
    "- Forward Selection (start from nothing and end until significant)\n",
    "- Backward Elimination (start with everything and end until no more can be removed)\n",
    "- Not always the best results...\n",
    "\n",
    "\n",
    "#### What is best subset regression and the pros and cons of it?\n",
    "- A brute-force like method of fitting *all possible regressions* or *all possible models*\n",
    "- Unlike stepwise, this method fits all possible models based on the variables specified, so you will get the best model possible\n",
    "![a_secret_easter_egg_i_like_apples](https://i.kym-cdn.com/photos/images/newsfeed/001/718/138/147.jpg)\n",
    "\n",
    "\n",
    "\n",
    "#### What is an assumption we make when we fit linear regression models?\n",
    "- Make sure the input matrix is full rank.\n",
    "  - Question: _What happens when input matrix is not full rank?_\n",
    "- Well, the data has to be linearly separable. \n",
    "- Does this also apply to other models too...? (Recall SVM and kernel function which we can use)\n",
    "- Perhaps another model might suit the dataset... (Trees, Neural Networks, Clustering, etc...)\n",
    "\n",
    "\n",
    "#### If you were to use a decision tree, how would you compare between two different fits? \n",
    "- Look at Gini Impurity (probability of an incorrectly classified instance)\n",
    "\n",
    "\n",
    "#### How about baselines or other predictive machine learning models?\n",
    "- Precision, Recall, Classification Accuracy...\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Fitting a GLM with Python\n",
    "**Since MAST30027 is not a pre-requisuite, we will not cover this nor do we expect students to use GLMs. However, those who wish to experiment with GLMs using Python may go through this section.**\n",
    "\n",
    "Let's go through an example:\n",
    "- The `passenger_count` attribute is discrete and non-negative. If we were to predict it, a linear model will not be sufficient. \n",
    "- We know that a Poisson distribution takes in non-negative integer values, so we can use the Poisson family of GLMs to model this. \n",
    "- We will use `total_amount, trip_distance, VendorID` as our regressors.\n",
    "\n",
    "Summary:\n",
    "- GLM's allow us to express relationships in a linear and additive way like normal linear regression.\n",
    "- However, it might be the case that the underlying true relationship is neither linear nor additive. \n",
    "- The transformation is done through a *link function* (in this case, Poisson).\n",
    "\n",
    "Why would we use try and use Poisson? The distribution of `passenger_count` is frequency based greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T07:56:43.429657Z",
     "start_time": "2022-07-18T07:56:43.206205Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.api import families\n",
    "\n",
    "# convert VendorID to categorical\n",
    "df['VendorID'] = df['VendorID'] == 1\n",
    "\n",
    "# statsmodels glm\n",
    "fit = glm(\n",
    "    formula=\"passenger_count ~ total_amount + trip_distance + VendorID\",\n",
    "    data=df, \n",
    "    family=families.Poisson()\n",
    ").fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1c6f7b18ea35922dad1f927d5d0123541ee5478d7a9729c6a2c6ed680be427a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
